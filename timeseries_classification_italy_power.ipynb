{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *\n",
    "from config import *\n",
    "from dataloaders import *\n",
    "from transform_data import *\n",
    "from model_part_italy import *\n",
    "from callbacks import *\n",
    "\n",
    "from functools import partial\n",
    "from scipy.io import arff\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/ItalyPowerDemand_TRAIN.txt', header=None,delim_whitespace=True)\n",
    "df_test = pd.read_csv('data/ItalyPowerDemand_TEST.txt', header=None, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.710518</td>\n",
       "      <td>-1.183320</td>\n",
       "      <td>-1.372442</td>\n",
       "      <td>-1.593083</td>\n",
       "      <td>-1.467002</td>\n",
       "      <td>-1.372442</td>\n",
       "      <td>-1.088760</td>\n",
       "      <td>0.045967</td>\n",
       "      <td>0.928532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.647477</td>\n",
       "      <td>-0.269235</td>\n",
       "      <td>-0.206195</td>\n",
       "      <td>0.613330</td>\n",
       "      <td>1.369815</td>\n",
       "      <td>1.464375</td>\n",
       "      <td>1.054613</td>\n",
       "      <td>0.581810</td>\n",
       "      <td>0.172048</td>\n",
       "      <td>-0.269235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.993009</td>\n",
       "      <td>-1.426786</td>\n",
       "      <td>-1.579884</td>\n",
       "      <td>-1.605401</td>\n",
       "      <td>-1.630917</td>\n",
       "      <td>-1.375754</td>\n",
       "      <td>-1.018526</td>\n",
       "      <td>-0.355102</td>\n",
       "      <td>0.716583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486936</td>\n",
       "      <td>0.563485</td>\n",
       "      <td>0.614518</td>\n",
       "      <td>0.308322</td>\n",
       "      <td>0.257289</td>\n",
       "      <td>1.099327</td>\n",
       "      <td>1.048295</td>\n",
       "      <td>0.691066</td>\n",
       "      <td>-0.048906</td>\n",
       "      <td>-0.380618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.319067</td>\n",
       "      <td>0.569774</td>\n",
       "      <td>0.195128</td>\n",
       "      <td>-0.085856</td>\n",
       "      <td>-0.179518</td>\n",
       "      <td>-0.273180</td>\n",
       "      <td>-0.085856</td>\n",
       "      <td>-1.397118</td>\n",
       "      <td>-1.116134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.554164</td>\n",
       "      <td>-0.741487</td>\n",
       "      <td>-0.741487</td>\n",
       "      <td>-0.741487</td>\n",
       "      <td>-1.116134</td>\n",
       "      <td>-0.460503</td>\n",
       "      <td>0.476113</td>\n",
       "      <td>2.349344</td>\n",
       "      <td>2.255682</td>\n",
       "      <td>1.600052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.812444</td>\n",
       "      <td>-1.157553</td>\n",
       "      <td>-1.416385</td>\n",
       "      <td>-1.531421</td>\n",
       "      <td>-1.502662</td>\n",
       "      <td>-1.416385</td>\n",
       "      <td>-1.646458</td>\n",
       "      <td>-0.467335</td>\n",
       "      <td>0.654269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740547</td>\n",
       "      <td>0.884342</td>\n",
       "      <td>0.884342</td>\n",
       "      <td>0.683028</td>\n",
       "      <td>0.625510</td>\n",
       "      <td>0.424197</td>\n",
       "      <td>-0.007190</td>\n",
       "      <td>-0.035949</td>\n",
       "      <td>0.107847</td>\n",
       "      <td>-0.266022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.972840</td>\n",
       "      <td>-1.390518</td>\n",
       "      <td>-1.536705</td>\n",
       "      <td>-1.620240</td>\n",
       "      <td>-1.620240</td>\n",
       "      <td>-1.453169</td>\n",
       "      <td>-0.993724</td>\n",
       "      <td>0.050469</td>\n",
       "      <td>0.635218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321960</td>\n",
       "      <td>0.489031</td>\n",
       "      <td>0.614334</td>\n",
       "      <td>1.303502</td>\n",
       "      <td>1.240850</td>\n",
       "      <td>1.073779</td>\n",
       "      <td>0.551682</td>\n",
       "      <td>0.426379</td>\n",
       "      <td>-0.179253</td>\n",
       "      <td>-0.638698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  1.0 -0.710518 -1.183320 -1.372442 -1.593083 -1.467002 -1.372442 -1.088760   \n",
       "1  1.0 -0.993009 -1.426786 -1.579884 -1.605401 -1.630917 -1.375754 -1.018526   \n",
       "2  2.0  1.319067  0.569774  0.195128 -0.085856 -0.179518 -0.273180 -0.085856   \n",
       "3  2.0 -0.812444 -1.157553 -1.416385 -1.531421 -1.502662 -1.416385 -1.646458   \n",
       "4  1.0 -0.972840 -1.390518 -1.536705 -1.620240 -1.620240 -1.453169 -0.993724   \n",
       "\n",
       "         8         9   ...        15        16        17        18        19  \\\n",
       "0  0.045967  0.928532  ... -0.647477 -0.269235 -0.206195  0.613330  1.369815   \n",
       "1 -0.355102  0.716583  ...  0.486936  0.563485  0.614518  0.308322  0.257289   \n",
       "2 -1.397118 -1.116134  ... -0.554164 -0.741487 -0.741487 -0.741487 -1.116134   \n",
       "3 -0.467335  0.654269  ...  0.740547  0.884342  0.884342  0.683028  0.625510   \n",
       "4  0.050469  0.635218  ...  0.321960  0.489031  0.614334  1.303502  1.240850   \n",
       "\n",
       "         20        21        22        23        24  \n",
       "0  1.464375  1.054613  0.581810  0.172048 -0.269235  \n",
       "1  1.099327  1.048295  0.691066 -0.048906 -0.380618  \n",
       "2 -0.460503  0.476113  2.349344  2.255682  1.600052  \n",
       "3  0.424197 -0.007190 -0.035949  0.107847 -0.266022  \n",
       "4  1.073779  0.551682  0.426379 -0.179253 -0.638698  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add a categorical variable\n",
    "countries = ['Germany', 'US']\n",
    "household_income = ['low', 'high']\n",
    "df_train[\"country\"] = np.random.choice(countries, len(df_train))\n",
    "df_test[\"country\"] = np.random.choice(countries, len(df_test))\n",
    "df_train[\"household_income\"] = np.random.choice(household_income, len(df_train))\n",
    "df_test[\"household_income\"] = np.random.choice(household_income, len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.710518</td>\n",
       "      <td>-1.183320</td>\n",
       "      <td>-1.372442</td>\n",
       "      <td>-1.593083</td>\n",
       "      <td>-1.467002</td>\n",
       "      <td>-1.372442</td>\n",
       "      <td>-1.088760</td>\n",
       "      <td>0.045967</td>\n",
       "      <td>0.928532</td>\n",
       "      <td>1.086133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.647477</td>\n",
       "      <td>-0.269235</td>\n",
       "      <td>-0.206195</td>\n",
       "      <td>0.613330</td>\n",
       "      <td>1.369815</td>\n",
       "      <td>1.464375</td>\n",
       "      <td>1.054613</td>\n",
       "      <td>0.581810</td>\n",
       "      <td>0.172048</td>\n",
       "      <td>-0.269235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.993009</td>\n",
       "      <td>-1.426786</td>\n",
       "      <td>-1.579884</td>\n",
       "      <td>-1.605401</td>\n",
       "      <td>-1.630917</td>\n",
       "      <td>-1.375754</td>\n",
       "      <td>-1.018526</td>\n",
       "      <td>-0.355102</td>\n",
       "      <td>0.716583</td>\n",
       "      <td>1.201393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486936</td>\n",
       "      <td>0.563485</td>\n",
       "      <td>0.614518</td>\n",
       "      <td>0.308322</td>\n",
       "      <td>0.257289</td>\n",
       "      <td>1.099327</td>\n",
       "      <td>1.048295</td>\n",
       "      <td>0.691066</td>\n",
       "      <td>-0.048906</td>\n",
       "      <td>-0.380618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.319067</td>\n",
       "      <td>0.569774</td>\n",
       "      <td>0.195128</td>\n",
       "      <td>-0.085856</td>\n",
       "      <td>-0.179518</td>\n",
       "      <td>-0.273180</td>\n",
       "      <td>-0.085856</td>\n",
       "      <td>-1.397118</td>\n",
       "      <td>-1.116134</td>\n",
       "      <td>-0.741487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.554164</td>\n",
       "      <td>-0.741487</td>\n",
       "      <td>-0.741487</td>\n",
       "      <td>-0.741487</td>\n",
       "      <td>-1.116134</td>\n",
       "      <td>-0.460503</td>\n",
       "      <td>0.476113</td>\n",
       "      <td>2.349344</td>\n",
       "      <td>2.255682</td>\n",
       "      <td>1.600052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.812444</td>\n",
       "      <td>-1.157553</td>\n",
       "      <td>-1.416385</td>\n",
       "      <td>-1.531421</td>\n",
       "      <td>-1.502662</td>\n",
       "      <td>-1.416385</td>\n",
       "      <td>-1.646458</td>\n",
       "      <td>-0.467335</td>\n",
       "      <td>0.654269</td>\n",
       "      <td>1.056896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740547</td>\n",
       "      <td>0.884342</td>\n",
       "      <td>0.884342</td>\n",
       "      <td>0.683028</td>\n",
       "      <td>0.625510</td>\n",
       "      <td>0.424197</td>\n",
       "      <td>-0.007190</td>\n",
       "      <td>-0.035949</td>\n",
       "      <td>0.107847</td>\n",
       "      <td>-0.266022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.972840</td>\n",
       "      <td>-1.390518</td>\n",
       "      <td>-1.536705</td>\n",
       "      <td>-1.620240</td>\n",
       "      <td>-1.620240</td>\n",
       "      <td>-1.453169</td>\n",
       "      <td>-0.993724</td>\n",
       "      <td>0.050469</td>\n",
       "      <td>0.635218</td>\n",
       "      <td>1.032011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321960</td>\n",
       "      <td>0.489031</td>\n",
       "      <td>0.614334</td>\n",
       "      <td>1.303502</td>\n",
       "      <td>1.240850</td>\n",
       "      <td>1.073779</td>\n",
       "      <td>0.551682</td>\n",
       "      <td>0.426379</td>\n",
       "      <td>-0.179253</td>\n",
       "      <td>-0.638698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-1.037930</td>\n",
       "      <td>-1.301658</td>\n",
       "      <td>-1.469485</td>\n",
       "      <td>-1.589361</td>\n",
       "      <td>-1.613336</td>\n",
       "      <td>-1.517435</td>\n",
       "      <td>-1.061905</td>\n",
       "      <td>-0.006993</td>\n",
       "      <td>1.215746</td>\n",
       "      <td>1.143820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424562</td>\n",
       "      <td>0.448537</td>\n",
       "      <td>0.448537</td>\n",
       "      <td>0.304686</td>\n",
       "      <td>0.448537</td>\n",
       "      <td>1.215746</td>\n",
       "      <td>0.664315</td>\n",
       "      <td>0.352636</td>\n",
       "      <td>-0.102894</td>\n",
       "      <td>-0.510474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-0.373579</td>\n",
       "      <td>-0.986632</td>\n",
       "      <td>-1.446422</td>\n",
       "      <td>-1.676316</td>\n",
       "      <td>-1.752948</td>\n",
       "      <td>-1.369790</td>\n",
       "      <td>-0.910000</td>\n",
       "      <td>-0.986632</td>\n",
       "      <td>-0.220316</td>\n",
       "      <td>0.852527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469369</td>\n",
       "      <td>0.775895</td>\n",
       "      <td>0.929158</td>\n",
       "      <td>0.392737</td>\n",
       "      <td>0.162842</td>\n",
       "      <td>0.009579</td>\n",
       "      <td>-0.373579</td>\n",
       "      <td>1.312316</td>\n",
       "      <td>0.929158</td>\n",
       "      <td>-0.067053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-1.159152</td>\n",
       "      <td>-1.301400</td>\n",
       "      <td>-1.524933</td>\n",
       "      <td>-1.565575</td>\n",
       "      <td>-1.606217</td>\n",
       "      <td>-1.443648</td>\n",
       "      <td>-1.077867</td>\n",
       "      <td>0.019474</td>\n",
       "      <td>0.730715</td>\n",
       "      <td>1.177780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710393</td>\n",
       "      <td>0.486861</td>\n",
       "      <td>0.446218</td>\n",
       "      <td>0.486861</td>\n",
       "      <td>0.263328</td>\n",
       "      <td>0.893284</td>\n",
       "      <td>0.669751</td>\n",
       "      <td>0.466540</td>\n",
       "      <td>-0.122774</td>\n",
       "      <td>-0.651123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.694919</td>\n",
       "      <td>-1.235829</td>\n",
       "      <td>-1.416133</td>\n",
       "      <td>-1.506285</td>\n",
       "      <td>-1.506285</td>\n",
       "      <td>-1.506285</td>\n",
       "      <td>-1.055526</td>\n",
       "      <td>-1.010450</td>\n",
       "      <td>-0.063857</td>\n",
       "      <td>1.108115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612280</td>\n",
       "      <td>1.063039</td>\n",
       "      <td>0.927811</td>\n",
       "      <td>0.612280</td>\n",
       "      <td>0.251673</td>\n",
       "      <td>0.161522</td>\n",
       "      <td>0.026294</td>\n",
       "      <td>0.657356</td>\n",
       "      <td>0.206598</td>\n",
       "      <td>-0.199085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.984033</td>\n",
       "      <td>0.169661</td>\n",
       "      <td>-0.519423</td>\n",
       "      <td>-0.832643</td>\n",
       "      <td>-0.895287</td>\n",
       "      <td>-0.707355</td>\n",
       "      <td>-0.707355</td>\n",
       "      <td>-1.772304</td>\n",
       "      <td>-0.895287</td>\n",
       "      <td>0.482881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.519423</td>\n",
       "      <td>-0.644711</td>\n",
       "      <td>-0.707355</td>\n",
       "      <td>-0.769999</td>\n",
       "      <td>-0.707355</td>\n",
       "      <td>-0.268847</td>\n",
       "      <td>0.232305</td>\n",
       "      <td>2.424845</td>\n",
       "      <td>1.923693</td>\n",
       "      <td>1.171965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7   \\\n",
       "0  -0.710518 -1.183320 -1.372442 -1.593083 -1.467002 -1.372442 -1.088760   \n",
       "1  -0.993009 -1.426786 -1.579884 -1.605401 -1.630917 -1.375754 -1.018526   \n",
       "2   1.319067  0.569774  0.195128 -0.085856 -0.179518 -0.273180 -0.085856   \n",
       "3  -0.812444 -1.157553 -1.416385 -1.531421 -1.502662 -1.416385 -1.646458   \n",
       "4  -0.972840 -1.390518 -1.536705 -1.620240 -1.620240 -1.453169 -0.993724   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "62 -1.037930 -1.301658 -1.469485 -1.589361 -1.613336 -1.517435 -1.061905   \n",
       "63 -0.373579 -0.986632 -1.446422 -1.676316 -1.752948 -1.369790 -0.910000   \n",
       "64 -1.159152 -1.301400 -1.524933 -1.565575 -1.606217 -1.443648 -1.077867   \n",
       "65 -0.694919 -1.235829 -1.416133 -1.506285 -1.506285 -1.506285 -1.055526   \n",
       "66  0.984033  0.169661 -0.519423 -0.832643 -0.895287 -0.707355 -0.707355   \n",
       "\n",
       "          8         9         10  ...        15        16        17        18  \\\n",
       "0   0.045967  0.928532  1.086133  ... -0.647477 -0.269235 -0.206195  0.613330   \n",
       "1  -0.355102  0.716583  1.201393  ...  0.486936  0.563485  0.614518  0.308322   \n",
       "2  -1.397118 -1.116134 -0.741487  ... -0.554164 -0.741487 -0.741487 -0.741487   \n",
       "3  -0.467335  0.654269  1.056896  ...  0.740547  0.884342  0.884342  0.683028   \n",
       "4   0.050469  0.635218  1.032011  ...  0.321960  0.489031  0.614334  1.303502   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "62 -0.006993  1.215746  1.143820  ...  0.424562  0.448537  0.448537  0.304686   \n",
       "63 -0.986632 -0.220316  0.852527  ...  0.469369  0.775895  0.929158  0.392737   \n",
       "64  0.019474  0.730715  1.177780  ...  0.710393  0.486861  0.446218  0.486861   \n",
       "65 -1.010450 -0.063857  1.108115  ...  0.612280  1.063039  0.927811  0.612280   \n",
       "66 -1.772304 -0.895287  0.482881  ... -0.519423 -0.644711 -0.707355 -0.769999   \n",
       "\n",
       "          19        20        21        22        23        24  \n",
       "0   1.369815  1.464375  1.054613  0.581810  0.172048 -0.269235  \n",
       "1   0.257289  1.099327  1.048295  0.691066 -0.048906 -0.380618  \n",
       "2  -1.116134 -0.460503  0.476113  2.349344  2.255682  1.600052  \n",
       "3   0.625510  0.424197 -0.007190 -0.035949  0.107847 -0.266022  \n",
       "4   1.240850  1.073779  0.551682  0.426379 -0.179253 -0.638698  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "62  0.448537  1.215746  0.664315  0.352636 -0.102894 -0.510474  \n",
       "63  0.162842  0.009579 -0.373579  1.312316  0.929158 -0.067053  \n",
       "64  0.263328  0.893284  0.669751  0.466540 -0.122774 -0.651123  \n",
       "65  0.251673  0.161522  0.026294  0.657356  0.206598 -0.199085  \n",
       "66 -0.707355 -0.268847  0.232305  2.424845  1.923693  1.171965  \n",
       "\n",
       "[67 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[:, 1:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:, 1:-2].values.reshape(-1, 1, 24)\n",
    "x_test = df_test.iloc[:, 1:-2].values.reshape(-1, 1, 24)\n",
    "\n",
    "y_train = df_train.iloc[:, 0].values-1\n",
    "y_test = df_test.iloc[:, 0].values-1\n",
    "\n",
    "emb_vars_train = df_train.iloc[:, -2:].values\n",
    "emb_vars_test = df_test.iloc[:, -2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vars_train, emb_vars_test, dict_embs, dict_inv_embs = cat_transform(emb_vars_train, emb_vars_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = DEVICE\n",
    "datasets = create_datasets(x_train, emb_vars_train, y_train,\n",
    "             x_test, emb_vars_test, y_test,\n",
    "             valid_pct=VAL_SIZE, seed=1234)\n",
    "data = DataBunch(*create_loaders(datasets, bs=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_feat = x_train.shape[1]\n",
    "emb_dims = [(len(dict_embs[0]), EMB_DIMS), (len(dict_embs[1]), EMB_DIMS)]\n",
    "\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier_CNN_small(raw_feat, emb_dims, num_classes).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier_CNN_small(\n",
       "  (raw): Sequential(\n",
       "    (0): Conv1d(1, 128, kernel_size=(23,), stride=(1,))\n",
       "    (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Flatten()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Dropout(p=0.5, inplace=False)\n",
       "    (7): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "  )\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(2, 5)\n",
       "    (1): Embedding(2, 5)\n",
       "  )\n",
       "  (emb_out): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to check to which value we should set our learning rate, we can use the handy *LR_Find* Callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(model, opt, loss_func, data)\n",
    "run = Runner(cb_funcs=[LR_Find, Recorder])\n",
    "run.fit(1000, learn)\n",
    "run.recorder.plot(skip_last=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our learning rate should be ideally somewhere around 2e-3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.6898276131108122, tensor(0.5283)]\n",
      "valid: [0.6995464733668736, tensor(0.4286)]\n",
      "train: [0.6861856568534419, tensor(0.5283)]\n",
      "valid: [0.684891973223005, tensor(0.5000)]\n",
      "train: [0.6782473438190963, tensor(0.5660)]\n",
      "valid: [0.6716748646327427, tensor(0.5714)]\n",
      "train: [0.6653764112940375, tensor(0.6415)]\n",
      "valid: [0.658198424748012, tensor(0.5714)]\n",
      "train: [0.664700706050081, tensor(0.6038)]\n",
      "valid: [0.6428552355085101, tensor(0.5714)]\n",
      "train: [0.6674122360517394, tensor(0.6038)]\n",
      "valid: [0.6250144413539341, tensor(0.5714)]\n",
      "train: [0.6411245813909566, tensor(0.6792)]\n",
      "valid: [0.6064740589686802, tensor(0.5714)]\n",
      "train: [0.6345404858859081, tensor(0.6604)]\n",
      "valid: [0.5841319220406669, tensor(0.7143)]\n",
      "train: [0.6129934922704157, tensor(0.6604)]\n",
      "valid: [0.5580510411943708, tensor(0.7143)]\n",
      "train: [0.5784456864842829, tensor(0.7547)]\n",
      "valid: [0.5291423116411481, tensor(0.7143)]\n",
      "train: [0.5652149488341134, tensor(0.7547)]\n",
      "valid: [0.49724899019513813, tensor(0.7143)]\n",
      "train: [0.5319615130154591, tensor(0.8302)]\n",
      "valid: [0.46321708815438406, tensor(0.8571)]\n",
      "train: [0.5032828348987507, tensor(0.7736)]\n",
      "valid: [0.42433626311165945, tensor(0.8571)]\n",
      "train: [0.48394411914753466, tensor(0.8113)]\n",
      "valid: [0.3679247924259731, tensor(0.9286)]\n",
      "train: [0.4155989592930056, tensor(0.8302)]\n",
      "valid: [0.30038721220833914, tensor(1.)]\n",
      "train: [0.4214742768485591, tensor(0.8302)]\n",
      "valid: [0.23935350349971227, tensor(1.)]\n",
      "train: [0.3592792367035488, tensor(0.8679)]\n",
      "valid: [0.1889801025390625, tensor(1.)]\n",
      "train: [0.28734628209527935, tensor(0.9057)]\n",
      "valid: [0.14091913189206803, tensor(1.)]\n",
      "train: [0.2756769432211822, tensor(0.9057)]\n",
      "valid: [0.10096809693745204, tensor(1.)]\n",
      "train: [0.27015376540849795, tensor(0.8491)]\n",
      "valid: [0.07200307505471366, tensor(1.)]\n",
      "train: [0.266599529194382, tensor(0.8868)]\n",
      "valid: [0.06009722181728908, tensor(1.)]\n",
      "train: [0.22281821268909383, tensor(0.9057)]\n",
      "valid: [0.042014517954417636, tensor(1.)]\n",
      "train: [0.16821859467704342, tensor(0.9623)]\n",
      "valid: [0.027473926544189453, tensor(1.)]\n",
      "train: [0.1628400334772074, tensor(0.9623)]\n",
      "valid: [0.01931677120072501, tensor(1.)]\n",
      "train: [0.21584948053899802, tensor(0.9245)]\n",
      "valid: [0.020985062633241926, tensor(1.)]\n",
      "train: [0.1143945298104916, tensor(0.9811)]\n",
      "valid: [0.025050044059753418, tensor(1.)]\n",
      "train: [0.14109062698652158, tensor(0.9434)]\n",
      "valid: [0.01998903921672276, tensor(1.)]\n",
      "train: [0.1679593931953862, tensor(0.9434)]\n",
      "valid: [0.01173718273639679, tensor(1.)]\n",
      "train: [0.06386729906190117, tensor(0.9623)]\n",
      "valid: [0.008834185877016612, tensor(1.)]\n",
      "train: [0.05450871305645637, tensor(1.)]\n",
      "valid: [0.008130919188261032, tensor(1.)]\n"
     ]
    }
   ],
   "source": [
    "cbfs = [Recorder, partial(AvgStatsCallback,adjusted_accu)]\n",
    "model = Classifier_CNN_small(raw_feat, emb_dims, num_classes).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=2e-3)\n",
    "learn = Learner(model, opt, loss_func, data)\n",
    "run = Runner(cb_funcs=cbfs)\n",
    "run.fit(30, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = run.predict(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9572400388726919"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(outs == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our embeddings. We defined to have 5 embeddings for each categorical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2240,  0.1337, -2.1963,  0.2495, -0.5241],\n",
       "        [-0.6942,  1.7485, -0.5922,  0.6028,  0.3194]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.6631, -0.3797,  0.1878,  0.6988,  0.2954],\n",
       "        [-0.2556,  1.0189, -1.0607, -1.5518, -0.0505]], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings[1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "330ccaa4a349b4a13daf4931e5f2f4adcbe68f446661c4f978ade16288ddaf4a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('dl_venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
